{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport string\nimport numpy as np\nimport random\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nfrom IPython.core.debugger import set_trace\nimport IPython\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-01T16:22:53.952835Z","iopub.execute_input":"2024-04-01T16:22:53.953360Z","iopub.status.idle":"2024-04-01T16:22:53.962015Z","shell.execute_reply.started":"2024-04-01T16:22:53.953314Z","shell.execute_reply":"2024-04-01T16:22:53.960315Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def get_alphabets_random(window, shift, text=None, reverse=False):\n    if text is not None:\n        shift = shift % len(text)\n        shifted_text = text[shift:] + text[:shift]\n        return f'Input: {text}\\nShifted: {shifted_text}'\n    \n    alphabets = string.ascii_lowercase\n    rand_indices = [random.randint(0, 25) for _ in range(window)]\n    \n    text = ''.join(list(map(lambda x: alphabets[x], rand_indices)))\n    \n    if reverse:\n        reversed_text = ''.join(list(reversed(list(text))))\n        return text, reversed_text\n        \n    shift = shift % len(text)\n    shifted_text = text[shift:] + text[:shift]\n    \n    return text, shifted_text\n\nget_alphabets_random(10, -2, reverse=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.398377Z","iopub.execute_input":"2024-04-01T16:18:00.399789Z","iopub.status.idle":"2024-04-01T16:18:00.416120Z","shell.execute_reply.started":"2024-04-01T16:18:00.399743Z","shell.execute_reply":"2024-04-01T16:18:00.414818Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('gkkroqlxtr', 'rtxlqorkkg')"},"metadata":{}}]},{"cell_type":"code","source":"def generate_training_data(window, shift, num_examples, reverse):\n    x = list(); y = list()\n    \n    for _ in range(num_examples):\n        text, shifted = get_alphabets_random(window, shift, reverse=reverse)\n        x.append(text); y.append(shifted)\n        \n    random_id = random.randint(0, len(x))\n    print(x[random_id], y[random_id])\n    \n    return x, y","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.417533Z","iopub.execute_input":"2024-04-01T16:18:00.418016Z","iopub.status.idle":"2024-04-01T16:18:00.429015Z","shell.execute_reply.started":"2024-04-01T16:18:00.417970Z","shell.execute_reply":"2024-04-01T16:18:00.427356Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def create_vocabulary():\n    unique_characters = list(string.ascii_lowercase)\n    char_to_id = {char:i for i, char in enumerate(unique_characters)}\n    id_to_char = {i: char for i, char in enumerate(unique_characters)}\n    \n    features_dim = len(unique_characters)\n    print(f'Number of features is {features_dim}')\n    return char_to_id, id_to_char, features_dim","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.430812Z","iopub.execute_input":"2024-04-01T16:18:00.431225Z","iopub.status.idle":"2024-04-01T16:18:00.442025Z","shell.execute_reply.started":"2024-04-01T16:18:00.431190Z","shell.execute_reply":"2024-04-01T16:18:00.440652Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"encode_text = lambda x: [char_to_id[_] for _ in x]\ndecode_text = lambda x_: [id_to_char[_] for _ in x_]","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.444134Z","iopub.execute_input":"2024-04-01T16:18:00.444635Z","iopub.status.idle":"2024-04-01T16:18:00.457377Z","shell.execute_reply.started":"2024-04-01T16:18:00.444590Z","shell.execute_reply":"2024-04-01T16:18:00.455775Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def encode_data(x, y, features_dim):\n    encoded_x = list(map(lambda x_: encode_text(x_), x))\n    encoded_y = list(map(lambda x_: encode_text(x_), y))\n    \n    one_hot_x = F.one_hot(torch.tensor(encoded_x), num_classes=features_dim)\n    one_hot_y = F.one_hot(torch.tensor(encoded_y), num_classes=features_dim)\n    \n    one_hot_y = one_hot_y.permute(1, 0, 2)\n    \n    return one_hot_x.to(torch.float32), one_hot_y.to(torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.458769Z","iopub.execute_input":"2024-04-01T16:18:00.459179Z","iopub.status.idle":"2024-04-01T16:18:00.470403Z","shell.execute_reply.started":"2024-04-01T16:18:00.459143Z","shell.execute_reply":"2024-04-01T16:18:00.468914Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"x, y = generate_training_data(10, -2, 10000, True)\nchar_to_id, id_to_char, features = create_vocabulary()\none_hot_x, one_hot_y = encode_data(x, y, features)\nprint(one_hot_x.dtype, one_hot_y.dtype)\n\nval_x, val_y = generate_training_data(10, -2, 1000, True)\nval_x, val_y = encode_data(val_x, val_y, features)\nprint(val_x.shape, val_y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.472177Z","iopub.execute_input":"2024-04-01T16:18:00.472681Z","iopub.status.idle":"2024-04-01T16:18:00.910368Z","shell.execute_reply.started":"2024-04-01T16:18:00.472648Z","shell.execute_reply":"2024-04-01T16:18:00.909056Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"mbokrqazub buzaqrkobm\nNumber of features is 26\ntorch.float32 torch.float32\nyfsnqdwjjz zjjwdqnsfy\ntorch.Size([1000, 10, 26]) torch.Size([10, 1000, 26])\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomData(Dataset):\n    def __init__(self, x_data, y_data):\n        super().__init__()\n        self.x_data = x_data\n        self.y_data = y_data\n        \n    def __len__(self):\n        return len(self.x_data)\n    \n    def __getitem__(self, idx):\n        return self.x_data[idx], self.y_data[:, idx, :]\n    \ndataset = CustomData(one_hot_x, one_hot_y)\nval_dataset = CustomData(val_x, val_y)\n\ntrain_loader = DataLoader(dataset, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.912114Z","iopub.execute_input":"2024-04-01T16:18:00.912933Z","iopub.status.idle":"2024-04-01T16:18:00.924855Z","shell.execute_reply.started":"2024-04-01T16:18:00.912891Z","shell.execute_reply":"2024-04-01T16:18:00.923364Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class AttentionModel(nn.Module):\n    def __init__(self, encoder_dim, decoder_dim, input_features_dim, output_features_dim, timesteps, num_training):\n        super().__init__()\n        self.timesteps = timesteps\n        self.input_features_dim = input_features_dim\n        \n        self.densor1 = nn.Linear(decoder_dim+(2*encoder_dim), 10)\n        self.tanh = nn.Tanh()\n        self.densor2 = nn.Linear(10, 1)\n        self.softmax = nn.Softmax(dim=1)\n        \n        self.pre_attention_lstm = nn.LSTM(input_size=input_features_dim, hidden_size=encoder_dim, batch_first=True, bidirectional=True)\n        self.post_attention_lstm = nn.LSTM(input_size=encoder_dim*2, hidden_size=decoder_dim, batch_first=True)\n        self.output_layer = nn.Linear(decoder_dim, output_features_dim)\n        \n        \n    def forward(self, x, s0, c0):\n        # x-> (B, timesteps, features) -> (128, 10, 26)\n        # s0, c0 -> (1, B, decoder_dim) -> (1, 128, 16)\n        #set_trace()\n        self.s = s0; self.c = c0\n        encoder_hidden_states, (hn, cn) = self.pre_attention_lstm(x) #hidden_states: (B, timesteps, encoder_dim*2) -> (128, 10, 16)\n        outputs = list()\n        \n        for t in range(self.timesteps):\n            context = self.one_step_attention(encoder_hidden_states) # (B, timesteps, 2*encoder_dim)\n            _, (self.s, self.c )= self.post_attention_lstm(context, (self.s, self.c)) # _ -> (B, timesteps, decoder_dim)\n            output = self.output_layer(self.s) # (1, B, output_features_dim) -> (1, 128, 26)\n            outputs.append(output) # (timesteps, B, output_features_dim) -> (10, 128, 26)\n        \n        return outputs\n    \n    def one_step_attention(self, encoder_hidden_states):\n        # encoder_Hidden_states -> (B, timesteps, 2*encoder_dim) -> (128, 10, 16)\n        # self.s -> (1, B, decoder_dim)\n        # 1. first the hidden state for decoder must be repeated to match the hidden states of encoder\n        # self.s -> (timesteps, B, decoder_dim) -> permute -> (B, timesteps, decoder_dim)\n        # 2. then concatenate the hidden state for decoder and the hidden state for encoder -> (B, timesteps, 2*encoder_dim + decoder_dim)\n        # pass it through the first dense layer\n        # pass it through the second dense layer\n        # use softmax to decide which hidden state of encoder is the most important\n        # use dot product to find the important hidden state of encoder and feed it as input to the decoder\n        hidden_decoder = self.s.repeat(10, 1, 1).permute(1, 0, 2) # (B, timesteps, decoder_dim) -> (128, 10, 16)\n        concat = torch.concatenate([encoder_hidden_states, hidden_decoder], dim=-1) # (B, timesteps, 2*encoder_dim + decoder_dim) -> (128, 10, 32)\n        e = self.tanh(self.densor1(concat)) # (B, timesteps, 10) -> (128, 10, 10)\n        energies = self.softmax(self.densor2(e)) # (B, timesteps, 1) -> (128, 10, 1)\n        # let's if without permute in next step if the code converges\n        energies = energies.repeat(1, 1, 10).permute(0, 2, 1) # (B, timesteps, 10) -> (B, 10, 10)\n        context = torch.bmm(energies, encoder_hidden_states) # (B, timesteps, timesteps) @ (B, timesteps, 2*encoder_dim) -> (B, timesteps, 2*encoder_dim)\n        \n        return context\n        \n    def predict(self, x):\n        assert len(x) == self.timesteps\n        encoded = encode_text(x)\n        one_hot = F.one_hot(torch.tensor(encoded), num_classes=self.input_features_dim)\n        s0 = torch.zeros(1, 1, decoder_dim); c0 = torch.zeros(1, 1, decoder_dim)\n        one_hot = one_hot.unsqueeze(0)\n        pred = self.forward(one_hot.to(torch.float32), s0, c0)\n        pred = ''.join(decode_text([torch.argmax(t, dim=-1).tolist()[0][0] for t in pred]))\n        return pred","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.926995Z","iopub.execute_input":"2024-04-01T16:18:00.927688Z","iopub.status.idle":"2024-04-01T16:18:00.948295Z","shell.execute_reply.started":"2024-04-01T16:18:00.927646Z","shell.execute_reply":"2024-04-01T16:18:00.947202Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def calculate_loss(y_true, y_pred):\n    ce = nn.CrossEntropyLoss()\n    total = 0\n    for target, logit in zip(list(y_true), list(y_pred)):\n        loss = ce(logit[0], target)\n        total += loss\n        \n    return total","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.951485Z","iopub.execute_input":"2024-04-01T16:18:00.954730Z","iopub.status.idle":"2024-04-01T16:18:00.963666Z","shell.execute_reply.started":"2024-04-01T16:18:00.954672Z","shell.execute_reply":"2024-04-01T16:18:00.962363Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"imp = list()\n\ndef hook_function(module, input, output):\n    if not am.training:\n        imp.append(output[0].flatten().tolist())","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.965260Z","iopub.execute_input":"2024-04-01T16:18:00.965734Z","iopub.status.idle":"2024-04-01T16:18:00.974241Z","shell.execute_reply.started":"2024-04-01T16:18:00.965703Z","shell.execute_reply":"2024-04-01T16:18:00.973313Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"encoder_dim = 8\ndecoder_dim = 16\ninput_features_dim = features\noutput_features_dim = features\ntimesteps = 10\nnum_training = 10000\nepochs = 40\n\nattention_dict = dict()\n\ns0, c0 = torch.zeros(1, num_training, decoder_dim), torch.zeros(1, num_training, decoder_dim)\n\nam = AttentionModel(encoder_dim, decoder_dim, input_features_dim, output_features_dim, timesteps, num_training)\nopt = optim.Adam(am.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.975537Z","iopub.execute_input":"2024-04-01T16:18:00.977010Z","iopub.status.idle":"2024-04-01T16:18:00.990132Z","shell.execute_reply.started":"2024-04-01T16:18:00.976947Z","shell.execute_reply":"2024-04-01T16:18:00.988736Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"for name, layer in am.named_children():\n    if name == 'softmax':\n        print(layer)\n        handle = layer.register_forward_hook(hook_function)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:00.992875Z","iopub.execute_input":"2024-04-01T16:18:00.993900Z","iopub.status.idle":"2024-04-01T16:18:01.002880Z","shell.execute_reply.started":"2024-04-01T16:18:00.993866Z","shell.execute_reply":"2024-04-01T16:18:01.001023Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Softmax(dim=1)\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(epochs):\n    am.train()\n    train_loss = list()\n    for i, (inputs, target) in enumerate(train_loader):\n        #set_trace()\n        target = target.permute(1, 0, 2)\n        batch_size = inputs.size(0)\n        s0 = torch.zeros(1, batch_size, decoder_dim); c0 = torch.zeros(1, batch_size, decoder_dim)\n        outputs = am(inputs, s0, c0)\n        \n        opt.zero_grad()\n        \n        total_loss = calculate_loss(target, outputs)\n        train_loss.append(total_loss)\n        \n        total_loss.backward()\n        opt.step()\n        \n    print(f'Epoch {epoch}:: Train Loss {torch.mean(torch.tensor(train_loss))}')\n    \n    am.eval()\n    with torch.no_grad():\n#         s0 = torch.zeros(1, 1000, decoder_dim); c0 = torch.zeros(1, 1000, decoder_dim)\n#         out = am(val_x, s0, c0)\n        \n#         val_loss = calculate_loss(val_y, out)\n        \n#         print(f'Epoch {epoch}:: Val Loss {val_loss}')\n        test = 'monojitcnn'\n        pred = am.predict(test)\n        print(f'Input {test} --> Output {pred}')\n        \n        attention_dict[f'Epoch {epoch}'] = np.array(imp)\n        imp = list()\n        print()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:18:06.672444Z","iopub.execute_input":"2024-04-01T16:18:06.672888Z","iopub.status.idle":"2024-04-01T16:20:37.170118Z","shell.execute_reply.started":"2024-04-01T16:18:06.672855Z","shell.execute_reply":"2024-04-01T16:20:37.169068Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 0:: Train Loss 32.56444549560547\nInput monojitcnn --> Output aaaaaaaaaa\n\nEpoch 1:: Train Loss 31.95025634765625\nInput monojitcnn --> Output dddddddddd\n\nEpoch 2:: Train Loss 31.396120071411133\nInput monojitcnn --> Output dddddddddd\n\nEpoch 3:: Train Loss 30.901729583740234\nInput monojitcnn --> Output nddddddddd\n\nEpoch 4:: Train Loss 30.532001495361328\nInput monojitcnn --> Output nccccccccc\n\nEpoch 5:: Train Loss 29.835437774658203\nInput monojitcnn --> Output dcccceeeee\n\nEpoch 6:: Train Loss 28.65953254699707\nInput monojitcnn --> Output nnnccfffff\n\nEpoch 7:: Train Loss 26.70486831665039\nInput monojitcnn --> Output nncceemmmm\n\nEpoch 8:: Train Loss 23.72628402709961\nInput monojitcnn --> Output nncbbommmm\n\nEpoch 9:: Train Loss 20.463516235351562\nInput monojitcnn --> Output nncbeoemmm\n\nEpoch 10:: Train Loss 17.198877334594727\nInput monojitcnn --> Output nnccioemmm\n\nEpoch 11:: Train Loss 14.16718578338623\nInput monojitcnn --> Output nnccijommm\n\nEpoch 12:: Train Loss 11.6624755859375\nInput monojitcnn --> Output nnccjjonmm\n\nEpoch 13:: Train Loss 9.458612442016602\nInput monojitcnn --> Output nnccijonjm\n\nEpoch 14:: Train Loss 7.668954372406006\nInput monojitcnn --> Output nnccijonjm\n\nEpoch 15:: Train Loss 6.071324348449707\nInput monojitcnn --> Output nnctojonjm\n\nEpoch 16:: Train Loss 4.995593547821045\nInput monojitcnn --> Output nnctijonjm\n\nEpoch 17:: Train Loss 3.9451193809509277\nInput monojitcnn --> Output nnctijonom\n\nEpoch 18:: Train Loss 3.2136876583099365\nInput monojitcnn --> Output nnctijonom\n\nEpoch 19:: Train Loss 2.6283977031707764\nInput monojitcnn --> Output nnctijonom\n\nEpoch 20:: Train Loss 2.188697576522827\nInput monojitcnn --> Output nnctijonom\n\nEpoch 21:: Train Loss 1.8366436958312988\nInput monojitcnn --> Output nnctijonom\n\nEpoch 22:: Train Loss 1.5624462366104126\nInput monojitcnn --> Output nnctijonom\n\nEpoch 23:: Train Loss 1.320288062095642\nInput monojitcnn --> Output nnctijonom\n\nEpoch 24:: Train Loss 1.1218825578689575\nInput monojitcnn --> Output nnctijonom\n\nEpoch 25:: Train Loss 0.9884556531906128\nInput monojitcnn --> Output nnctijonom\n\nEpoch 26:: Train Loss 0.8511389493942261\nInput monojitcnn --> Output nnctijonom\n\nEpoch 27:: Train Loss 0.7481856942176819\nInput monojitcnn --> Output nnctijonom\n\nEpoch 28:: Train Loss 0.6679373979568481\nInput monojitcnn --> Output nnctijonom\n\nEpoch 29:: Train Loss 0.5941560864448547\nInput monojitcnn --> Output nnctijonom\n\nEpoch 30:: Train Loss 0.5256525874137878\nInput monojitcnn --> Output nnctijonom\n\nEpoch 31:: Train Loss 0.5010809302330017\nInput monojitcnn --> Output nnctijonom\n\nEpoch 32:: Train Loss 0.43119218945503235\nInput monojitcnn --> Output nnctijonom\n\nEpoch 33:: Train Loss 0.38712024688720703\nInput monojitcnn --> Output nnctijonom\n\nEpoch 34:: Train Loss 0.3546544313430786\nInput monojitcnn --> Output nnctijonom\n\nEpoch 35:: Train Loss 0.3250959813594818\nInput monojitcnn --> Output nnctijonom\n\nEpoch 36:: Train Loss 0.2910902798175812\nInput monojitcnn --> Output nnctijonom\n\nEpoch 37:: Train Loss 0.2697089612483978\nInput monojitcnn --> Output nnctijonom\n\nEpoch 38:: Train Loss 0.2471645027399063\nInput monojitcnn --> Output nnctijonom\n\nEpoch 39:: Train Loss 0.22640042006969452\nInput monojitcnn --> Output nnctijonom\n\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.imshow(attention_dict['Epoch 39'], cmap='plasma')\nplt.title('Attention Heatmap for Reversing Input Sequence')\nplt.xticks(range(len(test)), labels=test)\nplt.yticks(range(len(test)), labels=test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:36:19.762544Z","iopub.execute_input":"2024-04-01T16:36:19.763021Z","iopub.status.idle":"2024-04-01T16:36:20.054583Z","shell.execute_reply.started":"2024-04-01T16:36:19.762988Z","shell.execute_reply":"2024-04-01T16:36:20.053003Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"for key in attention_dict:\n    plt.imshow(attention_dict[key], cmap='plasma')\n    plt.title(key)\n    plt.title('Attention Heatmap for Reversing Input Sequence')\n    plt.xticks(range(len(test)), labels=test)\n    plt.yticks(range(len(test)), labels=test)\n    plt.colorbar()\n    \n    file_name = f'{key}.png'\n    plt.savefig(f'/kaggle/working/{file_name}')\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:36:27.802155Z","iopub.execute_input":"2024-04-01T16:36:27.802610Z","iopub.status.idle":"2024-04-01T16:36:41.183906Z","shell.execute_reply.started":"2024-04-01T16:36:27.802576Z","shell.execute_reply":"2024-04-01T16:36:41.182498Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"frames = list()\n\nfor key in attention_dict:\n    img = Image.open(f'/kaggle/working/{key}.png')\n    img = img.convert('RGB')\n    \n    frames.append(img)\n    \nframes[0].save('reverse_animation.gif', save_all=True, append_images=frames[1:], duration=150, loop=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:36:58.201683Z","iopub.execute_input":"2024-04-01T16:36:58.202091Z","iopub.status.idle":"2024-04-01T16:37:00.374942Z","shell.execute_reply.started":"2024-04-01T16:36:58.202061Z","shell.execute_reply":"2024-04-01T16:37:00.373570Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"from matplotlib import colormaps\nlist(colormaps)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T16:25:51.023761Z","iopub.execute_input":"2024-04-01T16:25:51.024321Z","iopub.status.idle":"2024-04-01T16:25:51.036683Z","shell.execute_reply.started":"2024-04-01T16:25:51.024266Z","shell.execute_reply":"2024-04-01T16:25:51.035358Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"['magma',\n 'inferno',\n 'plasma',\n 'viridis',\n 'cividis',\n 'twilight',\n 'twilight_shifted',\n 'turbo',\n 'Blues',\n 'BrBG',\n 'BuGn',\n 'BuPu',\n 'CMRmap',\n 'GnBu',\n 'Greens',\n 'Greys',\n 'OrRd',\n 'Oranges',\n 'PRGn',\n 'PiYG',\n 'PuBu',\n 'PuBuGn',\n 'PuOr',\n 'PuRd',\n 'Purples',\n 'RdBu',\n 'RdGy',\n 'RdPu',\n 'RdYlBu',\n 'RdYlGn',\n 'Reds',\n 'Spectral',\n 'Wistia',\n 'YlGn',\n 'YlGnBu',\n 'YlOrBr',\n 'YlOrRd',\n 'afmhot',\n 'autumn',\n 'binary',\n 'bone',\n 'brg',\n 'bwr',\n 'cool',\n 'coolwarm',\n 'copper',\n 'cubehelix',\n 'flag',\n 'gist_earth',\n 'gist_gray',\n 'gist_heat',\n 'gist_ncar',\n 'gist_rainbow',\n 'gist_stern',\n 'gist_yarg',\n 'gnuplot',\n 'gnuplot2',\n 'gray',\n 'hot',\n 'hsv',\n 'jet',\n 'nipy_spectral',\n 'ocean',\n 'pink',\n 'prism',\n 'rainbow',\n 'seismic',\n 'spring',\n 'summer',\n 'terrain',\n 'winter',\n 'Accent',\n 'Dark2',\n 'Paired',\n 'Pastel1',\n 'Pastel2',\n 'Set1',\n 'Set2',\n 'Set3',\n 'tab10',\n 'tab20',\n 'tab20b',\n 'tab20c',\n 'magma_r',\n 'inferno_r',\n 'plasma_r',\n 'viridis_r',\n 'cividis_r',\n 'twilight_r',\n 'twilight_shifted_r',\n 'turbo_r',\n 'Blues_r',\n 'BrBG_r',\n 'BuGn_r',\n 'BuPu_r',\n 'CMRmap_r',\n 'GnBu_r',\n 'Greens_r',\n 'Greys_r',\n 'OrRd_r',\n 'Oranges_r',\n 'PRGn_r',\n 'PiYG_r',\n 'PuBu_r',\n 'PuBuGn_r',\n 'PuOr_r',\n 'PuRd_r',\n 'Purples_r',\n 'RdBu_r',\n 'RdGy_r',\n 'RdPu_r',\n 'RdYlBu_r',\n 'RdYlGn_r',\n 'Reds_r',\n 'Spectral_r',\n 'Wistia_r',\n 'YlGn_r',\n 'YlGnBu_r',\n 'YlOrBr_r',\n 'YlOrRd_r',\n 'afmhot_r',\n 'autumn_r',\n 'binary_r',\n 'bone_r',\n 'brg_r',\n 'bwr_r',\n 'cool_r',\n 'coolwarm_r',\n 'copper_r',\n 'cubehelix_r',\n 'flag_r',\n 'gist_earth_r',\n 'gist_gray_r',\n 'gist_heat_r',\n 'gist_ncar_r',\n 'gist_rainbow_r',\n 'gist_stern_r',\n 'gist_yarg_r',\n 'gnuplot_r',\n 'gnuplot2_r',\n 'gray_r',\n 'hot_r',\n 'hsv_r',\n 'jet_r',\n 'nipy_spectral_r',\n 'ocean_r',\n 'pink_r',\n 'prism_r',\n 'rainbow_r',\n 'seismic_r',\n 'spring_r',\n 'summer_r',\n 'terrain_r',\n 'winter_r',\n 'Accent_r',\n 'Dark2_r',\n 'Paired_r',\n 'Pastel1_r',\n 'Pastel2_r',\n 'Set1_r',\n 'Set2_r',\n 'Set3_r',\n 'tab10_r',\n 'tab20_r',\n 'tab20b_r',\n 'tab20c_r']"},"metadata":{}}]}]}