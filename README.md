# LSTM Attention Mechanism

This is a simple work to understand the working of Attention Mechanism in LSTM. This is a sequence to sequence architecture. 

## Reverse an input sequence
monojitcnn -> nnctijonom

![Alt Text](https://github.com/MonojitSarkar/attention-lstm-char-manipulation/blob/main/gifs/reverse_animation.gif)
