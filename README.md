# LSTM Attention Mechanism

This is a simple work to understand the working of Attention Mechanism in LSTM. This is a sequence to sequence architecture. 

## Reverse an input sequence
### Input: monojitcnn 
### Output: nnctijonom
![Alt Text](https://github.com/MonojitSarkar/attention-lstm-char-manipulation/blob/main/gifs/reverse_animation(1).gif)

## Left shift an input sequence by 4 characters
### Input: monojitcnn
### Output: jitcnnmono
![Alt Text](https://github.com/MonojitSarkar/attention-lstm-char-manipulation/blob/main/gifs/left_shift_animation.gif)


## Right shift an input sequence by 3 characters
### Input: monojitcnn
### Output: cnnmonojit
![Alt Text](https://github.com/MonojitSarkar/attention-lstm-char-manipulation/blob/main/gifs/right_shift_animation.gif)


## Sort digits in ascending order
### Input 1, 9, 4, 3, 8, 7, 5, 6
### Output 1, 3, 4, 5, 6, 7, 8, 9
![Alt Text](https://github.com/MonojitSarkar/attention-lstm-char-manipulation/blob/main/gifs/sort_digits_animation.gif)

## Human Readable Dates to Machine Translated Dates
### Input: Thrusday, October 13 2011
### Output 13-10-2011
![Alt Text](https://github.com/MonojitSarkar/attention-lstm-char-manipulation/blob/main/gifs/date_attention.gif)

### Input: 28 March 2005
### Output 28-03-2005
![Alt Text](https://github.com/MonojitSarkar/attention-lstm-char-manipulation/blob/main/gifs/date_attention_2.gif)

## Attention Heatmap for various Human Readable Date Formats
![Alt Text](https://github.com/MonojitSarkar/attention-lstm-char-manipulation/blob/main/gifs/attention_weights_different_formats.png)
