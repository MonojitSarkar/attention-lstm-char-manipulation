{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install faker\n!pip install babel","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:00.277164Z","iopub.execute_input":"2024-04-04T08:40:00.278110Z","iopub.status.idle":"2024-04-04T08:40:34.688768Z","shell.execute_reply.started":"2024-04-04T08:40:00.278067Z","shell.execute_reply":"2024-04-04T08:40:34.687065Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: faker in /opt/conda/lib/python3.10/site-packages (24.4.0)\nRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/lib/python3.10/site-packages (from faker) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\nRequirement already satisfied: babel in /opt/conda/lib/python3.10/site-packages (2.14.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport string\nimport numpy as np\nimport random\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nfrom IPython.core.debugger import set_trace\nimport IPython\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom faker import Faker\nimport random\nfrom babel.dates import format_date\nimport re\nimport itertools\nfrom datetime import date\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:34.691460Z","iopub.execute_input":"2024-04-04T08:40:34.691887Z","iopub.status.idle":"2024-04-04T08:40:37.331619Z","shell.execute_reply.started":"2024-04-04T08:40:34.691852Z","shell.execute_reply":"2024-04-04T08:40:37.329423Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"fake = Faker()\n\n# We need to seed these guys. For some reason I always use 101\nFaker.seed(101)\nrandom.seed(101)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-04T08:40:37.334193Z","iopub.execute_input":"2024-04-04T08:40:37.335047Z","iopub.status.idle":"2024-04-04T08:40:37.401318Z","shell.execute_reply.started":"2024-04-04T08:40:37.334990Z","shell.execute_reply":"2024-04-04T08:40:37.397249Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"FORMATS = ['short', # d/M/YY\n           'medium',\n           'long',\n           'full',\n           'd MMM YYY', \n           'd MMMM YYY',\n           'dd/MM/YYY',\n           'EE d, MMM YYY',\n           'EEEE d, MMMM YYY']","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:37.404908Z","iopub.execute_input":"2024-04-04T08:40:37.405510Z","iopub.status.idle":"2024-04-04T08:40:37.415830Z","shell.execute_reply.started":"2024-04-04T08:40:37.405466Z","shell.execute_reply":"2024-04-04T08:40:37.412826Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def random_date():\n    start_date = date(2000, 1, 1); end_date = date(2024, 1, 1)\n    #dt = fake.date_object()\n    dt = fake.date_between(start_date=start_date, end_date=end_date)\n\n    try:\n        date_ = format_date(dt, format=random.choice(FORMATS), locale='en')\n        human_readable = date_.lower().replace(',', '')\n        machine_readable = dt.isoformat()\n\n    except AttributeError as e:\n        return None, None, None\n\n    return human_readable, machine_readable, dt","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:37.417719Z","iopub.execute_input":"2024-04-04T08:40:37.418232Z","iopub.status.idle":"2024-04-04T08:40:37.430539Z","shell.execute_reply.started":"2024-04-04T08:40:37.418188Z","shell.execute_reply":"2024-04-04T08:40:37.428672Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def create_dataset(num_examples:int):\n    x = list(); y = list();\n    \n    for _ in range(num_examples):\n        hr, mr, _ = random_date()\n        hr = re.split(r'\\s|/', hr); mr = re.split(r'-', mr)\n        \n        x.append(hr); y.append(mr)\n    \n    return x, y","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:37.433943Z","iopub.execute_input":"2024-04-04T08:40:37.434485Z","iopub.status.idle":"2024-04-04T08:40:37.454654Z","shell.execute_reply.started":"2024-04-04T08:40:37.434438Z","shell.execute_reply":"2024-04-04T08:40:37.451961Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"human_readables, machine_readables = create_dataset(10000)\nhr_val, mr_val = create_dataset(1000)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:37.456570Z","iopub.execute_input":"2024-04-04T08:40:37.457004Z","iopub.status.idle":"2024-04-04T08:40:38.766738Z","shell.execute_reply.started":"2024-04-04T08:40:37.456945Z","shell.execute_reply":"2024-04-04T08:40:38.765542Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"max_len_hr = max(list(map(len, human_readables)))\nmax_len_hr","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:38.785481Z","iopub.execute_input":"2024-04-04T08:40:38.786477Z","iopub.status.idle":"2024-04-04T08:40:38.801073Z","shell.execute_reply.started":"2024-04-04T08:40:38.786436Z","shell.execute_reply":"2024-04-04T08:40:38.799382Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"hr_flattened = list(itertools.chain.from_iterable(human_readables))\nprint(len(hr_flattened))\nhr_vocab = list(set(hr_flattened))\nprint(len(hr_vocab))\n\nmr_flattened = list(itertools.chain.from_iterable(machine_readables))\nprint(len(mr_flattened))\nmr_vocab = list(set(mr_flattened))\nprint(len(mr_vocab))\n\nhr_to_id = {_:i+1 for i, _ in enumerate(hr_vocab)}\nid_to_hr = {i+1:_ for i, _ in enumerate(hr_vocab)}\nhr_to_id['<unk>'] = 0\nid_to_hr[0] = '<unk>'\n\nmr_to_id = {_:i+1 for i, _ in enumerate(mr_vocab)}\nid_to_mr = {i+1:_ for i, _ in enumerate(mr_vocab)}\nmr_to_id['<unk>'] = 0\nid_to_mr[0] = '<unk>'","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:59.255884Z","iopub.execute_input":"2024-04-04T08:40:59.256636Z","iopub.status.idle":"2024-04-04T08:40:59.282847Z","shell.execute_reply.started":"2024-04-04T08:40:59.256591Z","shell.execute_reply":"2024-04-04T08:40:59.281402Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"33294\n103\n30000\n55\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_sequences(hr, mr):\n    human_readable_sequences = [list(map(lambda x: hr_to_id[x], x)) for x in hr]\n    machine_readable_sequences = [list(map(lambda x: mr_to_id[x], x)) for x in mr]\n    print(human_readable_sequences[:5], machine_readable_sequences[:5], sep='\\n')\n    \n    return human_readable_sequences, machine_readable_sequences\n\nhuman_readable_sequences, machine_readable_sequences = get_sequences(human_readables, machine_readables)\nhr_val_sequences, mr_val_sequences = get_sequences(hr_val, mr_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:38.867673Z","iopub.execute_input":"2024-04-04T08:40:38.868163Z","iopub.status.idle":"2024-04-04T08:40:38.926435Z","shell.execute_reply.started":"2024-04-04T08:40:38.868124Z","shell.execute_reply":"2024-04-04T08:40:38.923919Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[[39, 68, 9, 102], [18, 24, 66, 53], [83, 61, 84], [49, 35, 15, 43], [24, 10, 36]]\n[[45, 17, 17], [46, 13, 51], [11, 51, 9], [33, 51, 6], [37, 51, 18]]\n[[58, 77, 98], [68, 67, 56], [23, 81, 7, 5], [81, 10, 103], [76, 59, 14, 43]]\n[[32, 31, 47], [54, 17, 36], [4, 25, 15], [52, 25, 18], [33, 9, 30]]\n","output_type":"stream"}]},{"cell_type":"code","source":"pad_sequences = lambda sequences: pad_sequence(list(map(torch.tensor, sequences)), batch_first=True)\n\nhr_sequences_padded = pad_sequences(human_readable_sequences)\nhr_val_sequences_padded = pad_sequences(hr_val_sequences)\n\nmachine_readable_sequences = torch.tensor(machine_readable_sequences)\nmr_val_sequences = torch.tensor(mr_val_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:38.928316Z","iopub.execute_input":"2024-04-04T08:40:38.929398Z","iopub.status.idle":"2024-04-04T08:40:39.118853Z","shell.execute_reply.started":"2024-04-04T08:40:38.929322Z","shell.execute_reply":"2024-04-04T08:40:39.108890Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class CustomData(Dataset):\n    def __init__(self, x_data, y_data):\n        super().__init__()\n        self.x_data = x_data\n        self.y_data = y_data\n        \n    def __len__(self):\n        return len(self.x_data)\n    \n    def __getitem__(self, idx):\n        return self.x_data[idx], self.y_data[idx]\n    \ndataset = CustomData(hr_sequences_padded, machine_readable_sequences)\nval_dataset = CustomData(hr_val_sequences_padded, mr_val_sequences)\n\ntrain_loader = DataLoader(dataset, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:39.123701Z","iopub.execute_input":"2024-04-04T08:40:39.124172Z","iopub.status.idle":"2024-04-04T08:40:39.135695Z","shell.execute_reply.started":"2024-04-04T08:40:39.124126Z","shell.execute_reply":"2024-04-04T08:40:39.133795Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"decode_text = lambda x_: [id_to_mr[_] for _ in x_]\ndecode_text(mr_val_sequences[0].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:39.161602Z","iopub.execute_input":"2024-04-04T08:40:39.162160Z","iopub.status.idle":"2024-04-04T08:40:39.172392Z","shell.execute_reply.started":"2024-04-04T08:40:39.162121Z","shell.execute_reply":"2024-04-04T08:40:39.170172Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"['2005', '07', '08']"},"metadata":{}}]},{"cell_type":"code","source":"class AttentionModel(nn.Module):\n    def __init__(self, encoder_vocab_size, decoder_vocab_size,\n                 encoder_dim, decoder_dim, input_features_dim, output_features_dim, \n                 timesteps_encoder, timesteps_decoder, num_training):\n        super().__init__()\n        self.timesteps_encoder = timesteps_encoder\n        self.timesteps_decoder = timesteps_decoder\n        self.input_features_dim = input_features_dim\n        self.encoder_vocab_size = encoder_vocab_size\n        self.decoder_vocab_size = decoder_vocab_size\n        \n        self.densor1 = nn.Linear(decoder_dim+(2*encoder_dim), 10)\n        self.tanh = nn.Tanh()\n        self.densor2 = nn.Linear(10, 1)\n        self.softmax = nn.Softmax(dim=1)\n        \n        self.encoder_emb = nn.Embedding(encoder_vocab_size, 32)\n        self.pre_attention_lstm = nn.LSTM(input_size=32, hidden_size=encoder_dim, batch_first=True, bidirectional=True)\n        \n        #self.decoder_emb = nn.Embedding(decoder_vocab_size, 32)\n        self.post_attention_lstm = nn.LSTM(input_size=encoder_dim*2, hidden_size=decoder_dim, batch_first=True)\n        self.output_layer = nn.Linear(decoder_dim, decoder_vocab_size)\n        \n        \n    def forward(self, x, s0, c0):\n        # x-> (B, timesteps, features) -> (128, 10, 26)\n        # s0, c0 -> (1, B, decoder_dim) -> (1, 128, 16)\n        #set_trace()\n        self.s = s0; self.c = c0\n        x = self.encoder_emb(x)\n        encoder_hidden_states, (hn, cn) = self.pre_attention_lstm(x) #hidden_states: (B, timesteps, encoder_dim*2) -> (128, 10, 16)\n        outputs = list()\n        \n        for t in range(self.timesteps_decoder):\n            context = self.one_step_attention(encoder_hidden_states) # (B, timesteps, 2*encoder_dim)\n            _, (self.s, self.c )= self.post_attention_lstm(context, (self.s, self.c)) # _ -> (B, timesteps, decoder_dim)\n            output = self.output_layer(self.s) # (1, B, output_features_dim) -> (1, 128, 26)\n            outputs.append(output) # (timesteps, B, output_features_dim) -> (10, 128, 26)\n        \n        return outputs\n    \n    def one_step_attention(self, encoder_hidden_states):\n        # encoder_Hidden_states -> (B, timesteps, 2*encoder_dim) -> (128, 10, 16)\n        # self.s -> (1, B, decoder_dim)\n        # 1. first the hidden state for decoder must be repeated to match the hidden states of encoder\n        # self.s -> (timesteps, B, decoder_dim) -> permute -> (B, timesteps, decoder_dim)\n        # 2. then concatenate the hidden state for decoder and the hidden state for encoder -> (B, timesteps, 2*encoder_dim + decoder_dim)\n        # pass it through the first dense layer\n        # pass it through the second dense layer\n        # use softmax to decide which hidden state of encoder is the most important\n        # use dot product to find the important hidden state of encoder and feed it as input to the decoder\n        hidden_decoder = self.s.repeat(self.timesteps_encoder, 1, 1).permute(1, 0, 2) # (B, timesteps, decoder_dim) -> (128, 10, 16)\n        concat = torch.concatenate([encoder_hidden_states, hidden_decoder], dim=-1) # (B, timesteps, 2*encoder_dim + decoder_dim) -> (128, 10, 32)\n        e = self.tanh(self.densor1(concat)) # (B, timesteps, 10) -> (128, 10, 10)\n        energies = self.softmax(self.densor2(e)) # (B, timesteps, 1) -> (128, 10, 1)\n        # let's if without permute in next step if the code converges\n        energies = energies.repeat(1, 1, self.timesteps_encoder).permute(0, 2, 1) # (B, timesteps, 10) -> (B, 10, 10)\n        context = torch.bmm(energies, encoder_hidden_states) # (B, timesteps, timesteps) @ (B, timesteps, 2*encoder_dim) -> (B, timesteps, 2*encoder_dim)\n        \n        return context\n        \n    def predict(self, test_input):\n        #assert len(test_input.split()) == self.timesteps_encoder\n        #out = torch.tensor([hr_to_id[x] for x in test_input.split()])\n        #out = pad_sequence(, batch_first=True)\n        s0 = torch.zeros(1, 1, decoder_dim); c0 = torch.zeros(1, 1, decoder_dim)\n        \n        pred = self.forward(test_input, s0, c0)\n        #set_trace()\n        pred = '-'.join(decode_text([torch.argmax(t, dim=-1).tolist()[0][0] for t in pred]))\n        return pred","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:39.176304Z","iopub.execute_input":"2024-04-04T08:40:39.176839Z","iopub.status.idle":"2024-04-04T08:40:39.203570Z","shell.execute_reply.started":"2024-04-04T08:40:39.176799Z","shell.execute_reply":"2024-04-04T08:40:39.202104Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def calculate_loss(y_true, y_pred):\n    ce = nn.CrossEntropyLoss()\n    total = 0\n    for target, logit in zip(list(y_true), list(y_pred)):\n        loss = ce(logit[0], target)\n        total += loss\n        \n    return total","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:40:39.205315Z","iopub.execute_input":"2024-04-04T08:40:39.206107Z","iopub.status.idle":"2024-04-04T08:40:39.222033Z","shell.execute_reply.started":"2024-04-04T08:40:39.206030Z","shell.execute_reply":"2024-04-04T08:40:39.220534Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"imp = list()\n\ndef hook_function(module, input, output):\n    if not am.training and heatmap:\n        #set_trace()\n        imp.append(output[0].flatten().tolist())","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:44:17.716815Z","iopub.execute_input":"2024-04-04T08:44:17.717273Z","iopub.status.idle":"2024-04-04T08:44:17.723879Z","shell.execute_reply.started":"2024-04-04T08:44:17.717239Z","shell.execute_reply":"2024-04-04T08:44:17.722405Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"encoder_dim = 8\ndecoder_dim = 16\ninput_features_dim = features = None\noutput_features_dim = features = None\nencoder_vocab_size, decoder_vocab_size = len(hr_to_id), len(mr_to_id)\ntimesteps_encoder = max_len_hr\ntimesteps_decoder = 3 # hard coding\nnum_training = 10000\nepochs = 40\nheatmap = False\n\nattention_dict = dict()\n\ns0, c0 = torch.zeros(1, num_training, decoder_dim), torch.zeros(1, num_training, decoder_dim)\n\nam = AttentionModel(encoder_vocab_size, decoder_vocab_size, encoder_dim, decoder_dim,\n                    input_features_dim, output_features_dim, \n                    timesteps_encoder, timesteps_decoder, num_training)\nopt = optim.Adam(am.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:44:18.097574Z","iopub.execute_input":"2024-04-04T08:44:18.098393Z","iopub.status.idle":"2024-04-04T08:44:18.113669Z","shell.execute_reply.started":"2024-04-04T08:44:18.098324Z","shell.execute_reply":"2024-04-04T08:44:18.110922Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"for name, layer in am.named_children():\n    if name == 'softmax':\n        print(layer)\n        handle = layer.register_forward_hook(hook_function)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:44:18.910036Z","iopub.execute_input":"2024-04-04T08:44:18.910753Z","iopub.status.idle":"2024-04-04T08:44:18.917983Z","shell.execute_reply.started":"2024-04-04T08:44:18.910705Z","shell.execute_reply":"2024-04-04T08:44:18.916826Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Softmax(dim=1)\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(epochs):\n    am.train()\n    train_loss = list()\n    for i, (inputs, target) in enumerate(train_loader):\n        #set_trace()\n        target = target.permute(1, 0)\n        batch_size = inputs.size(0)\n        s0 = torch.zeros(1, batch_size, decoder_dim); c0 = torch.zeros(1, batch_size, decoder_dim)\n        outputs = am(inputs, s0, c0)\n        \n        opt.zero_grad()\n        #set_trace()\n        total_loss = calculate_loss(target, outputs)\n        train_loss.append(total_loss)\n        \n        total_loss.backward()\n        opt.step()\n        \n    print(f'Epoch {epoch}:: Train Loss {torch.mean(torch.tensor(train_loss))}')\n    \n    am.eval()\n    with torch.no_grad():\n        s0 = torch.zeros(1, 1000, decoder_dim); c0 = torch.zeros(1, 1000, decoder_dim)\n        out = am(hr_val_sequences_padded, s0, c0)\n        \n        val_loss = calculate_loss(mr_val_sequences.permute(1, 0), out)\n        \n        print(f'Epoch {epoch}:: Val Loss {val_loss}')\n        \n        test_hr = ' '.join(hr_val[105])\n        actual = '-'.join(mr_val[105])\n        \n        \n        #set_trace()\n        heatmap = True\n        pred = am.predict(hr_val_sequences_padded[105:106])\n        heatmap = False\n        print(f'Input {test_hr} --> Output {pred} and Actual {actual}')\n        print()\n        \n        attention_dict[f'Epoch {epoch}'] = np.array(imp)\n        imp = list()\n        print()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:44:19.887577Z","iopub.execute_input":"2024-04-04T08:44:19.888798Z","iopub.status.idle":"2024-04-04T08:45:05.681892Z","shell.execute_reply.started":"2024-04-04T08:44:19.888749Z","shell.execute_reply":"2024-04-04T08:45:05.679811Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 0:: Train Loss 11.765419960021973\nEpoch 0:: Val Loss 11.27727222442627\nInput thursday october 13 2011 --> Output 10-12-12 and Actual 2011-10-13\n\n\nEpoch 1:: Train Loss 10.850275039672852\nEpoch 1:: Val Loss 10.281318664550781\nInput thursday october 13 2011 --> Output 05-12-12 and Actual 2011-10-13\n\n\nEpoch 2:: Train Loss 9.595226287841797\nEpoch 2:: Val Loss 8.922517776489258\nInput thursday october 13 2011 --> Output 2010-10-10 and Actual 2011-10-13\n\n\nEpoch 3:: Train Loss 8.444517135620117\nEpoch 3:: Val Loss 7.952767372131348\nInput thursday october 13 2011 --> Output 2007-12-08 and Actual 2011-10-13\n\n\nEpoch 4:: Train Loss 7.594306468963623\nEpoch 4:: Val Loss 7.220965385437012\nInput thursday october 13 2011 --> Output 2007-12-08 and Actual 2011-10-13\n\n\nEpoch 5:: Train Loss 6.918320178985596\nEpoch 5:: Val Loss 6.621483325958252\nInput thursday october 13 2011 --> Output 2011-02-28 and Actual 2011-10-13\n\n\nEpoch 6:: Train Loss 6.345347881317139\nEpoch 6:: Val Loss 6.098905563354492\nInput thursday october 13 2011 --> Output 2011-02-28 and Actual 2011-10-13\n\n\nEpoch 7:: Train Loss 5.838748455047607\nEpoch 7:: Val Loss 5.635252952575684\nInput thursday october 13 2011 --> Output 2011-10-28 and Actual 2011-10-13\n\n\nEpoch 8:: Train Loss 5.387460231781006\nEpoch 8:: Val Loss 5.2232232093811035\nInput thursday october 13 2011 --> Output 2011-10-28 and Actual 2011-10-13\n\n\nEpoch 9:: Train Loss 5.0057148933410645\nEpoch 9:: Val Loss 4.860461235046387\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 10:: Train Loss 4.664727210998535\nEpoch 10:: Val Loss 4.542672157287598\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 11:: Train Loss 4.35767126083374\nEpoch 11:: Val Loss 4.252765655517578\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 12:: Train Loss 4.050112724304199\nEpoch 12:: Val Loss 3.9389209747314453\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 13:: Train Loss 3.7590723037719727\nEpoch 13:: Val Loss 3.6702184677124023\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 14:: Train Loss 3.474208354949951\nEpoch 14:: Val Loss 3.413911819458008\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 15:: Train Loss 3.22556209564209\nEpoch 15:: Val Loss 3.1813230514526367\nInput thursday october 13 2011 --> Output 2011-10-19 and Actual 2011-10-13\n\n\nEpoch 16:: Train Loss 2.997385025024414\nEpoch 16:: Val Loss 2.954549789428711\nInput thursday october 13 2011 --> Output 2011-10-19 and Actual 2011-10-13\n\n\nEpoch 17:: Train Loss 2.7732975482940674\nEpoch 17:: Val Loss 2.729973316192627\nInput thursday october 13 2011 --> Output 2011-10-19 and Actual 2011-10-13\n\n\nEpoch 18:: Train Loss 2.5619730949401855\nEpoch 18:: Val Loss 2.516896963119507\nInput thursday october 13 2011 --> Output 2011-10-31 and Actual 2011-10-13\n\n\nEpoch 19:: Train Loss 2.351796865463257\nEpoch 19:: Val Loss 2.3038530349731445\nInput thursday october 13 2011 --> Output 2011-10-23 and Actual 2011-10-13\n\n\nEpoch 20:: Train Loss 2.1438980102539062\nEpoch 20:: Val Loss 2.088499069213867\nInput thursday october 13 2011 --> Output 2011-10-23 and Actual 2011-10-13\n\n\nEpoch 21:: Train Loss 1.94169020652771\nEpoch 21:: Val Loss 1.8743574619293213\nInput thursday october 13 2011 --> Output 2011-10-31 and Actual 2011-10-13\n\n\nEpoch 22:: Train Loss 1.7458406686782837\nEpoch 22:: Val Loss 1.6762804985046387\nInput thursday october 13 2011 --> Output 2011-10-31 and Actual 2011-10-13\n\n\nEpoch 23:: Train Loss 1.558459997177124\nEpoch 23:: Val Loss 1.4798033237457275\nInput thursday october 13 2011 --> Output 2011-10-31 and Actual 2011-10-13\n\n\nEpoch 24:: Train Loss 1.3679710626602173\nEpoch 24:: Val Loss 1.2961547374725342\nInput thursday october 13 2011 --> Output 2011-10-23 and Actual 2011-10-13\n\n\nEpoch 25:: Train Loss 1.1979660987854004\nEpoch 25:: Val Loss 1.133307933807373\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 26:: Train Loss 1.0472625494003296\nEpoch 26:: Val Loss 0.9770030379295349\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 27:: Train Loss 0.9078583717346191\nEpoch 27:: Val Loss 0.8528214693069458\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 28:: Train Loss 0.7752711176872253\nEpoch 28:: Val Loss 0.7111122012138367\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 29:: Train Loss 0.6418455243110657\nEpoch 29:: Val Loss 0.5778800249099731\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 30:: Train Loss 0.5280182957649231\nEpoch 30:: Val Loss 0.5012949109077454\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 31:: Train Loss 0.4566115438938141\nEpoch 31:: Val Loss 0.4430723190307617\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 32:: Train Loss 0.39986538887023926\nEpoch 32:: Val Loss 0.39408034086227417\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 33:: Train Loss 0.35411161184310913\nEpoch 33:: Val Loss 0.3632168173789978\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 34:: Train Loss 0.3219313323497772\nEpoch 34:: Val Loss 0.3288145959377289\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 35:: Train Loss 0.2874133586883545\nEpoch 35:: Val Loss 0.3033031225204468\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 36:: Train Loss 0.2592417895793915\nEpoch 36:: Val Loss 0.27985483407974243\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 37:: Train Loss 0.23703111708164215\nEpoch 37:: Val Loss 0.2587304711341858\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 38:: Train Loss 0.21786977350711823\nEpoch 38:: Val Loss 0.25049009919166565\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\nEpoch 39:: Train Loss 0.20127810537815094\nEpoch 39:: Val Loss 0.22586750984191895\nInput thursday october 13 2011 --> Output 2011-10-13 and Actual 2011-10-13\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.imshow(attention_dict['Epoch 39'], cmap='plasma')\nplt.title('Attention Heatmap for Reversing Input Sequence')\nplt.xticks(range(len(hr_val[105])), labels=hr_val[105])\nplt.yticks(range(len(mr_val[105])), labels=mr_val[105])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:45:26.420070Z","iopub.execute_input":"2024-04-04T08:45:26.420794Z","iopub.status.idle":"2024-04-04T08:45:26.655220Z","shell.execute_reply.started":"2024-04-04T08:45:26.420757Z","shell.execute_reply":"2024-04-04T08:45:26.653305Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"for key in attention_dict:\n    plt.imshow(attention_dict[key], cmap='plasma')\n    plt.title(key)\n    plt.title('Attention Heatmap')\n    plt.xticks(range(len(hr_val[105])), labels=hr_val[105])\n    plt.yticks(range(len(mr_val[105])), labels=mr_val[105])\n    plt.colorbar()\n    \n    file_name = f'{key}.png'\n    plt.savefig(f'/kaggle/working/{file_name}')\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:46:24.012445Z","iopub.execute_input":"2024-04-04T08:46:24.013767Z","iopub.status.idle":"2024-04-04T08:46:34.273562Z","shell.execute_reply.started":"2024-04-04T08:46:24.013714Z","shell.execute_reply":"2024-04-04T08:46:34.272368Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"frames = list()\n\nfor key in attention_dict:\n    img = Image.open(f'/kaggle/working/{key}.png')\n    img = img.convert('RGB')\n    \n    frames.append(img)\n    \nframes[0].save('date_attention.gif', save_all=True, append_images=frames[1:], duration=150, loop=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T08:46:55.622812Z","iopub.execute_input":"2024-04-04T08:46:55.623293Z","iopub.status.idle":"2024-04-04T08:46:57.812828Z","shell.execute_reply.started":"2024-04-04T08:46:55.623257Z","shell.execute_reply":"2024-04-04T08:46:57.811316Z"},"trusted":true},"execution_count":41,"outputs":[]}]}